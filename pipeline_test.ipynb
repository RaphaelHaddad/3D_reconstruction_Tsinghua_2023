{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Matching Challenge 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conda setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: 'conda-forge' already in 'channels' list, moving to the bottom\n",
      "Warning: 'nvidia' already in 'channels' list, moving to the bottom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!conda config --append channels conda-forge\n",
    "!conda config --append channels nvidia\n",
    "!conda install cudatoolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Linux\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Windows\n",
    "!FOR /F %k in (requirements.txt) DO ( if NOT # == %k ( pip install %k ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing some libs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing PyTorch + GPU availability (not mandatory):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.2+cu121\n",
      "**********\n",
      "CUDNN version: 8801\n",
      "Available GPU devices: 1\n",
      "Device Name: NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "CUDA is available\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from kp_imc23.compatibility import verify_compatiblity\n",
    "verify_compatiblity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Anaconda\\envs\\cuda_env\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\cuda_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\Anaconda\\envs\\cuda_env\\Lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "[2023/12/28 22:46:51 hloc WARNING] pycolmap is not installed, some features may not work.\n"
     ]
    }
   ],
   "source": [
    "from kp_imc23.pipeline import configurate\n",
    "\n",
    "paths = configurate(\n",
    "    data_dir=\"./\",\n",
    "    output_dir=\"./output\",\n",
    "    dataset=\"haiper\", \n",
    "    scene=\"bike\",\n",
    "    mode=\"train\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotate images\n",
      "WARNING:tensorflow:From d:\\Anaconda\\envs\\cuda_env\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rotating images: 100%|██████████████████████████| 15/15 [00:07<00:00,  2.00it/s]\n",
      "[2023/12/28 22:47:06 hloc INFO] Extracting local features with configuration:\n",
      "{'model': {'name': 'eigenplaces'},\n",
      " 'output': 'global-feats-eigenplaces',\n",
      " 'preprocessing': {'resize_max': 1024}}\n",
      "[2023/12/28 22:47:06 hloc INFO] Skipping the extraction.\n",
      "[2023/12/28 22:47:06 hloc INFO] Extracting image pairs from a retrieval database.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023/12/28 22:47:07 hloc INFO] Found 75 pairs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"outdoor\" weights)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Superglue images_rotated: 100%|█████████████████| 75/75 [00:13<00:00,  5.44it/s]\n",
      "Loftr images_rotated: 100%|█████████████████████| 75/75 [06:46<00:00,  5.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['image_076.jpeg', 'image_101.jpeg'], ['image_076.jpeg', 'image_049.jpeg'], ['image_076.jpeg', 'image_128.jpeg'], ['image_076.jpeg', 'image_038.jpeg'], ['image_076.jpeg', 'image_150.jpeg'], ['image_062.jpeg', 'image_004.jpeg'], ['image_062.jpeg', 'image_137.jpeg'], ['image_062.jpeg', 'image_088.jpeg'], ['image_062.jpeg', 'image_128.jpeg'], ['image_062.jpeg', 'image_038.jpeg'], ['image_038.jpeg', 'image_049.jpeg'], ['image_038.jpeg', 'image_004.jpeg'], ['image_038.jpeg', 'image_128.jpeg'], ['image_038.jpeg', 'image_139.jpeg'], ['image_038.jpeg', 'image_101.jpeg'], ['image_094.jpeg', 'image_088.jpeg'], ['image_094.jpeg', 'image_004.jpeg'], ['image_094.jpeg', 'image_062.jpeg'], ['image_094.jpeg', 'image_029.jpeg'], ['image_094.jpeg', 'image_150.jpeg'], ['image_101.jpeg', 'image_128.jpeg'], ['image_101.jpeg', 'image_139.jpeg'], ['image_101.jpeg', 'image_076.jpeg'], ['image_101.jpeg', 'image_088.jpeg'], ['image_101.jpeg', 'image_150.jpeg'], ['image_128.jpeg', 'image_101.jpeg'], ['image_128.jpeg', 'image_038.jpeg'], ['image_128.jpeg', 'image_049.jpeg'], ['image_128.jpeg', 'image_139.jpeg'], ['image_128.jpeg', 'image_088.jpeg'], ['image_049.jpeg', 'image_038.jpeg'], ['image_049.jpeg', 'image_128.jpeg'], ['image_049.jpeg', 'image_150.jpeg'], ['image_049.jpeg', 'image_076.jpeg'], ['image_049.jpeg', 'image_004.jpeg'], ['image_088.jpeg', 'image_150.jpeg'], ['image_088.jpeg', 'image_094.jpeg'], ['image_088.jpeg', 'image_128.jpeg'], ['image_088.jpeg', 'image_101.jpeg'], ['image_088.jpeg', 'image_004.jpeg'], ['image_139.jpeg', 'image_101.jpeg'], ['image_139.jpeg', 'image_038.jpeg'], ['image_139.jpeg', 'image_128.jpeg'], ['image_139.jpeg', 'image_076.jpeg'], ['image_139.jpeg', 'image_088.jpeg'], ['image_115.jpeg', 'image_150.jpeg'], ['image_115.jpeg', 'image_076.jpeg'], ['image_115.jpeg', 'image_101.jpeg'], ['image_115.jpeg', 'image_088.jpeg'], ['image_115.jpeg', 'image_139.jpeg'], ['image_004.jpeg', 'image_038.jpeg'], ['image_004.jpeg', 'image_062.jpeg'], ['image_004.jpeg', 'image_088.jpeg'], ['image_004.jpeg', 'image_128.jpeg'], ['image_004.jpeg', 'image_049.jpeg'], ['image_119.jpeg', 'image_137.jpeg'], ['image_119.jpeg', 'image_062.jpeg'], ['image_119.jpeg', 'image_004.jpeg'], ['image_119.jpeg', 'image_115.jpeg'], ['image_119.jpeg', 'image_088.jpeg'], ['image_150.jpeg', 'image_088.jpeg'], ['image_150.jpeg', 'image_049.jpeg'], ['image_150.jpeg', 'image_101.jpeg'], ['image_150.jpeg', 'image_128.jpeg'], ['image_150.jpeg', 'image_115.jpeg'], ['image_137.jpeg', 'image_062.jpeg'], ['image_137.jpeg', 'image_119.jpeg'], ['image_137.jpeg', 'image_139.jpeg'], ['image_137.jpeg', 'image_004.jpeg'], ['image_137.jpeg', 'image_101.jpeg'], ['image_029.jpeg', 'image_004.jpeg'], ['image_029.jpeg', 'image_094.jpeg'], ['image_029.jpeg', 'image_062.jpeg'], ['image_029.jpeg', 'image_038.jpeg'], ['image_029.jpeg', 'image_049.jpeg']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping images:   4%|█                          | 3/75 [00:00<00:02, 24.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biggest matches found: 1575\n",
      "Crop image: image_076.jpeg\n",
      "Biggest matches found: 5834\n",
      "Crop image: image_076.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping images:   8%|██▏                        | 6/75 [00:00<00:03, 19.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biggest matches found: 425\n",
      "Crop image: image_062.jpeg\n",
      "Biggest matches found: 4735\n",
      "Crop image: image_062.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping images:  20%|█████▏                    | 15/75 [00:00<00:02, 21.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biggest matches found: 2083\n",
      "Crop image: image_038.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping images:  24%|██████▏                   | 18/75 [00:00<00:02, 21.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biggest matches found: 4443\n",
      "Crop image: image_094.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping images:  32%|████████▎                 | 24/75 [00:01<00:02, 22.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biggest matches found: 396\n",
      "Crop image: image_101.jpeg\n",
      "Biggest matches found: 1572\n",
      "Crop image: image_101.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping images:  40%|██████████▍               | 30/75 [00:01<00:02, 22.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biggest matches found: 473\n",
      "Crop image: image_128.jpeg\n",
      "Biggest matches found: 520\n",
      "Crop image: image_128.jpeg\n",
      "Biggest matches found: 856\n",
      "Crop image: image_128.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping images:  44%|███████████▍              | 33/75 [00:01<00:01, 22.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biggest matches found: 2038\n",
      "Crop image: image_049.jpeg\n",
      "Biggest matches found: 896\n",
      "Crop image: image_088.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping images:  52%|█████████████▌            | 39/75 [00:01<00:01, 22.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biggest matches found: 4371\n",
      "Crop image: image_088.jpeg\n",
      "Biggest matches found: 216\n",
      "Crop image: image_139.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping images:  60%|███████████████▌          | 45/75 [00:02<00:01, 22.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biggest matches found: 355\n",
      "Crop image: image_139.jpeg\n",
      "Biggest matches found: 518\n",
      "Crop image: image_139.jpeg\n",
      "Biggest matches found: 1887\n",
      "Crop image: image_115.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping images:  68%|█████████████████▋        | 51/75 [00:02<00:01, 21.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biggest matches found: 3545\n",
      "Crop image: image_115.jpeg\n",
      "Biggest matches found: 1505\n",
      "Crop image: image_004.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping images:  76%|███████████████████▊      | 57/75 [00:02<00:00, 23.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biggest matches found: 4152\n",
      "Crop image: image_004.jpeg\n",
      "Biggest matches found: 2354\n",
      "Crop image: image_119.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping images:  84%|█████████████████████▊    | 63/75 [00:02<00:00, 22.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biggest matches found: 946\n",
      "Crop image: image_150.jpeg\n",
      "Biggest matches found: 1689\n",
      "Crop image: image_150.jpeg\n",
      "Biggest matches found: 2008\n",
      "Crop image: image_150.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping images:  92%|███████████████████████▉  | 69/75 [00:03<00:00, 22.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biggest matches found: 4850\n",
      "Crop image: image_137.jpeg\n",
      "Biggest matches found: 1934\n",
      "Crop image: image_029.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping images: 100%|██████████████████████████| 75/75 [00:03<00:00, 22.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biggest matches found: 2160\n",
      "Crop image: image_029.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from kp_imc23.preprocessing.main import preprocess\n",
    "\n",
    "# preprocess images\n",
    "keypoints, image_dir_used = preprocess(paths,args=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kp_imc23.matching.main import database_colmap_run\n",
    "\n",
    "# Database\n",
    "database_colmap_run(paths, image_dir_used, dataset, scene, keypoints, args=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
